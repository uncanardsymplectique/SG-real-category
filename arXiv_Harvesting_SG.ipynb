{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# math.SG : Récupération et formattage des données\n",
    "\n",
    "_Remarque._ \n",
    "- Année 2019 : articles no 6402 à 6855 (454 articles) \n",
    "- 2009 : articles no 2451 à 2778 (327 articles) \n",
    "- total (jusqu'au 19 mai 2020) : 0 à 7045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as libreq\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour les colonnes author/category\n",
    "def nb(x):\n",
    "    if type(x) == list: return len(x)\n",
    "    else: return 1\n",
    "\n",
    "def ODict2List(x,key):\n",
    "    if type(x) == list: return ' | '.join([x[i][key] for i in range(len(x))])\n",
    "    else: return x[key]\n",
    "    \n",
    "# transformer xml en dictionnaries    \n",
    "def entry2dict(entry):\n",
    "    return xmltodict.parse(entry, process_namespaces=True, namespaces=namespaces)['entry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in [0,2000,4000,6000]:\n",
    "\n",
    "    # Récupération sous la forme d'un fichier xml\n",
    "    with libreq.urlopen(f'http://export.arxiv.org/api/query?search_query=cat:math.SG&start={start}&max_results=2000&sortBy=submittedDate&sortOrder=ascending') as url:\n",
    "        r = url.read()\n",
    "        \n",
    "    # Enregistrer les fichiers xml (au cas où ... pas besoin de re-charger le serveur d'arXiv)\n",
    "    file = open(f'tmp/arXiv_SG_{start}.xml', 'wb')\n",
    "    file.write(r)\n",
    "    file.close()\n",
    "    \n",
    "    # attendre 20 secondes entre chaque requête\n",
    "    sleep(20)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des 4 fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespaces = {\n",
    "    'http://arxiv.org/schemas/atom': None,\n",
    "#    'http://a9.com/-/spec/opensearch/1.1/': None, # skip this namespace\n",
    "#    'http://www.w3.org/2005/Atom' : None,\n",
    "#    'http://a.com/': 'ns_a', # collapse \"http://a.com/\" -> \"ns_a\"\n",
    "}\n",
    "\n",
    "for start in [0,2000,4000,6000]:\n",
    "    \n",
    "    # sous la forme d'une unique chaîne de texte sans le \"</feed>\" de la fin\n",
    "    with open(f'tmp/arXiv_SG_{str(start)}.xml') as fd:\n",
    "        raw_string = fd.read()\n",
    "    raw_string = raw_string[:-9]\n",
    "    \n",
    "    # transformation en listes d'entrées puis en liste de dictionnaires\n",
    "    # penser à virer 1er élément de la liste qui n'est pas une entrée\n",
    "    list_of_papers = raw_string.split('<entry>')\n",
    "    list_of_papers = [\"<entry>\" + paper for paper in list_of_papers[1:]]\n",
    "    list_of_dicts = [entry2dict(paper) for paper in list_of_papers]\n",
    "\n",
    "    # transformation en dataframe\n",
    "    arXiv_df = pd.DataFrame(list_of_dicts)\n",
    "    arXiv_df = arXiv_df.drop(columns=['link','journal_ref', 'doi'])\n",
    "    \n",
    "    # remplace dictionnaire par unique entrée qui m'importe\n",
    "    # garder uniquement id dans \"id\"\n",
    "    arXiv_df['primary_category'] = arXiv_df['primary_category'].map(lambda dict: dict['@term'])\n",
    "    arXiv_df['id'] = arXiv_df['id'].map(lambda id: id[21:])\n",
    "    \n",
    "    # Ajout cols : nb version finale, nb d'auteurs\n",
    "    arXiv_df['final_version'] = arXiv_df['id'].map(lambda x: x[-1])\n",
    "    arXiv_df['nb_authors'] = arXiv_df['author'].map(lambda x: nb(x))\n",
    "    arXiv_df['nb_category'] = arXiv_df['category'].map(lambda x: nb(x))\n",
    "\n",
    "    # transforme le ODict des auteurs en une string, separation \"|\"\n",
    "    arXiv_df['list_authors'] = arXiv_df['author'].map(lambda x: ODict2List(x,'name'))\n",
    "    arXiv_df = arXiv_df.drop(columns=['author'])\n",
    "    arXiv_df['list_categories'] = arXiv_df['category'].map(lambda x: ODict2List(x,'@term'))\n",
    "    arXiv_df = arXiv_df.drop(columns=['category'])\n",
    "    \n",
    "    # Enregistrer en csv\n",
    "    arXiv_df.to_csv(f'tmp/arXiv_SG_{str(start)}_formatted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On rassemble tout en un unique dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "for start in [0,2000,4000,6000]:\n",
    "    df.append(pd.read_csv(f'tmp/arXiv_SG_{start}_formatted.csv'))\n",
    "    \n",
    "math_SG = pd.concat(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>updated</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>comment</th>\n",
       "      <th>final_version</th>\n",
       "      <th>nb_authors</th>\n",
       "      <th>nb_category</th>\n",
       "      <th>list_authors</th>\n",
       "      <th>list_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7066</th>\n",
       "      <td>1066</td>\n",
       "      <td>2006.03521v1</td>\n",
       "      <td>2020-06-05T15:56:26Z</td>\n",
       "      <td>2020-06-05T15:56:26Z</td>\n",
       "      <td>L-space knots have no essential Conway spheres</td>\n",
       "      <td>We prove that L-space knots do not have essent...</td>\n",
       "      <td>math.GT</td>\n",
       "      <td>22 pages, 11 color figures created with PSTric...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Tye Lidman | Allison H. Moore | Claudius Zibro...</td>\n",
       "      <td>math.GT | math.QA | math.SG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0            id               updated             published  \\\n",
       "7066        1066  2006.03521v1  2020-06-05T15:56:26Z  2020-06-05T15:56:26Z   \n",
       "\n",
       "                                               title  \\\n",
       "7066  L-space knots have no essential Conway spheres   \n",
       "\n",
       "                                                summary primary_category  \\\n",
       "7066  We prove that L-space knots do not have essent...          math.GT   \n",
       "\n",
       "                                                comment  final_version  \\\n",
       "7066  22 pages, 11 color figures created with PSTric...              1   \n",
       "\n",
       "      nb_authors  nb_category  \\\n",
       "7066           3            3   \n",
       "\n",
       "                                           list_authors  \\\n",
       "7066  Tye Lidman | Allison H. Moore | Claudius Zibro...   \n",
       "\n",
       "                  list_categories  \n",
       "7066  math.GT | math.QA | math.SG  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_SG.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_SG.to_csv('data/arXiv_SG_total_formatted.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
